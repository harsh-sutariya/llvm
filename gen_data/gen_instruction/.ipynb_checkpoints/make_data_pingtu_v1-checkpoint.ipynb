{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde8452d-d076-4a53-b032-b81920c26234",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "每一组数据只有一张图的问答，一般用于制造dpo的拼图数据\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a87e51-d207-4b9f-ad97-d60172439f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3216860-3650-4c66-b7df-d51cb7c3d106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62461\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/dpo_data_scripts/llava_dpo_data/llava62k_dpo_v3.json\", 'r', encoding='utf-8') as file:\n",
    "    dpo_data = json.load(file)\n",
    "print(len(dpo_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f2e21ef-fbf4-47b4-ba52-d1c1ca294fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '000000101979',\n",
       " 'image': 'coco/train2017/000000101979.jpg',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nHow many people are there in the image?'},\n",
       "  {'from': 'gpt', 'value': 'There are two people in the image.'},\n",
       "  {'from': 'human', 'value': 'Are the two people skiing or standing?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'The two people are skiing on a cross-country slope, traveling across the snowy field while holding ski poles.'},\n",
       "  {'from': 'human', 'value': 'What kind of landscape surrounds the skiers?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'The skiers are surrounded by a frozen landscape, which includes a snowy field, snow-covered slopes, and a mountain in the background.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'What type of skiing are the two people engaged in?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'The two people are engaged in cross-country skiing, as they are traveling across a snowy field with ski poles.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'What can you tell about the snow conditions in the image?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'The image shows significant snow cover on the slopes, field, and mountain, indicating that the area has experienced a good amount of snowfall. The presence of snow in the landscape makes it ideal for winter sports such as cross-country skiing. The snow appears to be sufficiently packed to provide a suitable skiing surface for cross-country skiers, allowing them to glide across the field smoothly.'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_data[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ffe20d-2f6e-48a3-84b5-efc386eeca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2195\n",
      "2195\n",
      "2195\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "textvqa 数据集全部都是以 <image>\\nProvide a one-sentence caption for the provided image.\\n 作为问题的开头\n",
    "\"\"\"\n",
    "count = 0\n",
    "count_convs = 0\n",
    "textvqa_data = []\n",
    "for data in dpo_data:\n",
    "    if data[\"image\"].split('/')[0] == 'textvqa':\n",
    "        textvqa_data.append(data)\n",
    "        if data[\"conversations\"][0]['value'].startswith('<image>\\n'):\n",
    "            count+=1\n",
    "        if len(data[\"conversations\"])==2:\n",
    "            count_convs += 1\n",
    "print(count)\n",
    "print(count_convs)\n",
    "print(len(textvqa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2007b961-db17-4218-ae50-9f21696a67be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36410\n",
      "36410\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "coco 数据集全部都是以 <image>\\n 或者是 <image> 作为问题的开头或者是结尾\n",
    "\"\"\"\n",
    "count = 0\n",
    "coco_data = []\n",
    "for data in dpo_data:\n",
    "    if data[\"image\"].split('/')[0] == 'coco':\n",
    "        coco_data.append(data)\n",
    "        if data[\"conversations\"][0]['value'].startswith('<image>\\n'):\n",
    "            count+=1\n",
    "        if data[\"conversations\"][0]['value'].endswith('<image>'):\n",
    "            count+=1\n",
    "print(count)\n",
    "print(len(coco_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3f442f-b2ed-4387-8c9d-0053eb3f413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ocr_vqa 全部都是以 <image>\\n 作为问题的开头\n",
    "\"\"\"\n",
    "count = 0\n",
    "ocr_vqa_data = []\n",
    "for data in dpo_data:\n",
    "    if data[\"image\"].split('/')[0] == 'ocr_vqa':\n",
    "        ocr_vqa_data.append(data)\n",
    "        if data[\"conversations\"][0]['value'].startswith('<image>\\n'):\n",
    "            count+=1\n",
    "print(count)\n",
    "print(len(ocr_vqa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8ed72a-20a6-4fc1-92ee-84d806323417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8642\n",
      "8642\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "vg 全部都是以 <image>\\n 作为问题的开头\n",
    "\"\"\"\n",
    "count = 0\n",
    "vg_data = []\n",
    "for data in dpo_data:\n",
    "    if data[\"image\"].split('/')[0] == 'vg':\n",
    "        vg_data.append(data)\n",
    "        if data[\"conversations\"][0]['value'].startswith('<image>\\n'):\n",
    "            count+=1\n",
    "print(count)\n",
    "print(len(vg_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f23de833-9e08-4dfd-bb76-1c2834f960e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7214\n",
      "7214\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gpa 全部都是以 <image>\\n 作为问题的开头\n",
    "\"\"\"\n",
    "count = 0\n",
    "statistic = 0\n",
    "gqa_data = []\n",
    "for data in dpo_data:\n",
    "    if data[\"image\"].split('/')[0] == 'gqa':\n",
    "        gqa_data.append(data)\n",
    "        if data[\"conversations\"][0]['value'].startswith('<image>\\n') and data[\"conversations\"][0]['value'].endswith('Answer the question using a single word or phrase.'):\n",
    "            count+=1\n",
    "print(count)\n",
    "print(len(gqa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9147d9d2-9bcb-49a6-8e4f-2734312eabaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481519eb-0a51-428d-b85c-b8c3837e541d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584481c9-9ca7-48fb-a9fc-ba7d4b5b986e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b7f1c-b2b1-441b-850d-dbcd70369bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c4f8d2-7019-4e89-84b7-ca1585e82307",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "从 llava665k 中选取了 62k 的数据，并组合 多轮对话 拼图数据\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "127e2262-b826-4cc5-a6af-2bdf9ecefc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_companions(input_str, str_list, count=1):\n",
    "    filtered_list = [s for s in str_list if s != input_str]\n",
    "    return random.sample(filtered_list, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5ca5338-2ee3-4471-b02d-674c846793ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def resize_and_pad(image, target_size):\n",
    "    \"\"\"Resize and pad an image to the target size.\"\"\"\n",
    "    img_ratio = image.width / image.height\n",
    "    target_ratio = target_size[0] / target_size[1]\n",
    "\n",
    "    if img_ratio > target_ratio:\n",
    "        new_width = target_size[0]\n",
    "        new_height = int(new_width / img_ratio)\n",
    "    else:\n",
    "        new_height = target_size[1]\n",
    "        new_width = int(new_height * img_ratio)\n",
    "\n",
    "    resized_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    new_image = Image.new(\"RGB\", target_size, (255, 255, 255))\n",
    "    # paste_x = (target_size[0] - new_width) // 2\n",
    "    # paste_y = (target_size[1] - new_height) // 2\n",
    "    paste_x = 0\n",
    "    paste_y = 0\n",
    "    new_image.paste(resized_image, (paste_x, paste_y))\n",
    "    return new_image\n",
    "\n",
    "def combine_images_with_labels(image_paths, output_path, target_size=(448, 448), margin=40):\n",
    "    # # 获取提问的图像的大小\n",
    "    # resize_size = Image.open(image_paths[image_index-1]).size\n",
    "    # print(resize_size)\n",
    "    # # Load images and resize them\n",
    "    # images = [Image.open(image_path).resize(resize_size) for image_path in image_paths]\n",
    "    # num_images = len(images)\n",
    "\n",
    "    images = [resize_and_pad(Image.open(image_path), target_size) for image_path in image_paths]\n",
    "    num_images = len(images)\n",
    "\n",
    "    resize_size = target_size\n",
    "    # Calculate combined image size\n",
    "    if num_images == 2 or num_images == 3:\n",
    "        combined_width = resize_size[0] * num_images + margin * (num_images - 1)\n",
    "        combined_height = resize_size[1] + margin  # Add margin for labels\n",
    "    elif num_images == 4:\n",
    "        combined_width = resize_size[0] * 2 + margin\n",
    "        combined_height = resize_size[1] * 2 + margin * 2  # Add margin for labels\n",
    "    elif num_images == 6:\n",
    "        combined_width = resize_size[0] * 3 + margin * 2\n",
    "        combined_height = resize_size[1] * 2 + margin * 2  # Add margin for labels\n",
    "    elif num_images == 9:\n",
    "        combined_width = resize_size[0] * 3 + margin * 2\n",
    "        combined_height = resize_size[1] * 3 + margin * 3  # Add margin for labels\n",
    "    else:\n",
    "        raise ValueError(\"The number of images must be 2, 3, 4, 6, or 9.\")\n",
    "    \n",
    "    # Create new image with white background\n",
    "    combined_image = Image.new('RGB', (combined_width, combined_height), (255, 255, 255))\n",
    "    \n",
    "    # Define positions for each image and label\n",
    "    positions = []\n",
    "    labels = []\n",
    "    if num_images == 2 or num_images == 3:\n",
    "        for i in range(num_images):\n",
    "            x = i * (resize_size[0] + margin)\n",
    "            y = 0+margin\n",
    "            positions.append((x, y))\n",
    "            labels.append(f\"Image{i+1}\")\n",
    "    elif num_images == 4:\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                x = j * (resize_size[0] + margin)\n",
    "                y = i * (resize_size[1] + margin)+margin\n",
    "                positions.append((x, y))\n",
    "                labels.append(f\"Image{2*i+j+1}\")\n",
    "    elif num_images == 6:\n",
    "        for i in range(2):\n",
    "            for j in range(3):\n",
    "                x = j * (resize_size[0] + margin)\n",
    "                y = i * (resize_size[1] + margin)+margin\n",
    "                positions.append((x, y))\n",
    "                labels.append(f\"Image{3*i+j+1}\")\n",
    "    elif num_images == 9:\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                x = j * (resize_size[0] + margin)\n",
    "                y = i * (resize_size[1] + margin)+margin\n",
    "                positions.append((x, y))\n",
    "                labels.append(f\"Image{3*i+j+1}\")\n",
    "    \n",
    "    # Paste images and draw labels\n",
    "    draw = ImageDraw.Draw(combined_image)\n",
    "    font = ImageFont.truetype(\"../Arial.ttf\", 36)  # Load a larger TrueType font, or use another available font\n",
    "\n",
    "    for img, pos, label in zip(images, positions, labels):\n",
    "        combined_image.paste(img, pos)\n",
    "        # Calculate label position in the left top corner\n",
    "        label_x = pos[0] + 20  # Add some padding from the left edge\n",
    "        label_y = pos[1] - 40  # Add some padding from the top edge\n",
    "        draw.text((label_x, label_y), label, (0, 0, 0), font=font)\n",
    "    \n",
    "    # Save the combined image\n",
    "    combined_image.save(output_path)\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# image_list = [\n",
    "#     \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/car1.jpg\",\n",
    "#     \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/car2.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/newcar3.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/newcar4.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/apple.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/bear.png\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/apple.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/apple.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/apple.jpg\",\n",
    "# ]\n",
    "# output_path = \"./combined_image_9.png\"\n",
    "# combine_images_with_labels(image_list, output_path)\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9237eeba-6d00-4b48-84ce-ad6631abf159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2195\n",
      "36410\n",
      "8000\n",
      "8642\n",
      "7214\n",
      "62461\n"
     ]
    }
   ],
   "source": [
    "textvqa_image = []\n",
    "for data in textvqa_data:\n",
    "    textvqa_image.append(data[\"image\"])\n",
    "print(len(textvqa_image))\n",
    "\n",
    "coco_image = []\n",
    "for data in coco_data:\n",
    "    coco_image.append(data[\"image\"])\n",
    "print(len(coco_image))\n",
    "\n",
    "ocr_vqa_image = []\n",
    "for data in ocr_vqa_data:\n",
    "    ocr_vqa_image.append(data[\"image\"])\n",
    "print(len(ocr_vqa_image))\n",
    "\n",
    "vq_image = []\n",
    "for data in vg_data:\n",
    "    vq_image.append(data[\"image\"])\n",
    "print(len(vq_image))\n",
    "\n",
    "gqa_image = []\n",
    "for data in gqa_data:\n",
    "    gqa_image.append(data[\"image\"])\n",
    "print(len(gqa_image))\n",
    "\n",
    "all_images = textvqa_image + coco_image + ocr_vqa_image + vq_image + gqa_image\n",
    "print(len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9b81778-701e-436b-a283-17476884b21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2195it [03:08, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2195\n",
      "Data has been written to ./mix_textvqa_data.json\n"
     ]
    }
   ],
   "source": [
    "mix_textvqa_data = []\n",
    "for index, data in tqdm(enumerate(textvqa_data)):\n",
    "    if index<1000:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 1)\n",
    "    elif index<1300:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 2)\n",
    "    elif index<1600:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 3)\n",
    "    elif index<1900:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 5)\n",
    "    elif index<2195:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 8)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "    new_image_list = []\n",
    "    for img_path in image_list:\n",
    "        new_image_list.append('/mnt/petrelfs/liuziyu/V3Det/LLaVA/scripts/v1_5/data/cl_data/' + img_path)\n",
    "    output_path = f'/mnt/hwfile/mllm/liuziyu/RLHF_data/RLHF_combined_pics_v3/textvqa_{index}.jpg'\n",
    "    combine_images_with_labels(new_image_list, output_path)\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', '<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    data['image'] = output_path\n",
    "    data[\"image_list\"] = new_image_list\n",
    "    mix_textvqa_data.append(data)\n",
    "\n",
    "print(len(mix_textvqa_data))\n",
    "output_json_path = \"./mix_textvqa_data.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(mix_textvqa_data, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30020291-bcf3-401c-b125-0ff5ed8b6400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [05:24, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "Data has been written to ./mix_ocr_vqa_data.json\n"
     ]
    }
   ],
   "source": [
    "mix_ocr_vqa_data = []\n",
    "for index, data in tqdm(enumerate(ocr_vqa_data)):\n",
    "    if index<3800:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 1)\n",
    "    elif index<4900:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 2)\n",
    "    elif index<6000:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 3)\n",
    "    elif index<7100:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 5)\n",
    "    elif index<8000:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 8)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "    new_image_list = []\n",
    "    for img_path in image_list:\n",
    "        new_image_list.append('/mnt/petrelfs/liuziyu/V3Det/LLaVA/scripts/v1_5/data/cl_data/' + img_path)\n",
    "    output_path = f'/mnt/hwfile/mllm/liuziyu/RLHF_data/RLHF_combined_pics_v3/ocrvqa_{index}.jpg'\n",
    "    combine_images_with_labels(new_image_list, output_path)\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                convs['value'] = '<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    data['image'] = output_path\n",
    "    data[\"image_list\"] = new_image_list\n",
    "    mix_ocr_vqa_data.append(data)\n",
    "    \n",
    "print(len(mix_ocr_vqa_data))\n",
    "output_json_path = \"./mix_ocr_vqa_data.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(mix_ocr_vqa_data, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a8dbf79-7450-4fa8-ab15-9cb4831d5c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7214it [05:34, 21.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7214\n",
      "Data has been written to ./mix_gqa_data.json\n"
     ]
    }
   ],
   "source": [
    "mix_gqa_data = []\n",
    "for index, data in tqdm(enumerate(gqa_data)):\n",
    "    if index<3200:\n",
    "        image_list = find_companions(data['image'], gqa_image, 1)\n",
    "    elif index<4300:\n",
    "        image_list = find_companions(data['image'], gqa_image, 2)\n",
    "    elif index<5400:\n",
    "        image_list = find_companions(data['image'], gqa_image, 3)\n",
    "    elif index<6300:\n",
    "        image_list = find_companions(data['image'], gqa_image, 5)\n",
    "    elif index<7214:\n",
    "        image_list = find_companions(data['image'], gqa_image, 8)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "    new_image_list = []\n",
    "    for img_path in image_list:\n",
    "        new_image_list.append('/mnt/petrelfs/liuziyu/V3Det/LLaVA/scripts/v1_5/data/cl_data/' + img_path)\n",
    "    output_path = f'/mnt/hwfile/mllm/liuziyu/RLHF_data/RLHF_combined_pics_v3/gqa_{index}.jpg'\n",
    "    combine_images_with_labels(new_image_list, output_path)\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                convs['value'] = '<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    data['image'] = output_path\n",
    "    data[\"image_list\"] = new_image_list\n",
    "    mix_gqa_data.append(data)\n",
    "    \n",
    "print(len(mix_gqa_data))\n",
    "output_json_path = \"./mix_gqa_data.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(mix_gqa_data, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89d9f61b-8d4d-4250-9456-4d9d5dd33db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def contains_bbox(s):\n",
    "    bbox_pattern = r'\\[\\s*\\d+(\\.\\d+)?,\\s*\\d+(\\.\\d+)?,\\s*\\d+(\\.\\d+)?,\\s*\\d+(\\.\\d+)?\\s*\\]'\n",
    "    match = re.search(bbox_pattern, s)\n",
    "    if match:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5afe784-a0d4-4efe-9b49-21b3b4c6aed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36410it [23:17, 26.05it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31565\n",
      "Data has been written to ./mix_coco_data.json\n"
     ]
    }
   ],
   "source": [
    "mix_coco_data = []\n",
    "for index, data in tqdm(enumerate(coco_data)):\n",
    "    choose_flase = True\n",
    "    for conv in data[\"conversations\"]:\n",
    "        conv_value = conv[\"value\"]\n",
    "        if contains_bbox(conv_value):\n",
    "            choose_flase = False\n",
    "    if choose_flase == True: \n",
    "        if index<18000:\n",
    "            image_list = find_companions(data['image'], coco_image, 1)\n",
    "        elif index<23000:\n",
    "            image_list = find_companions(data['image'], coco_image, 2)\n",
    "        elif index<28000:\n",
    "            image_list = find_companions(data['image'], coco_image, 3)\n",
    "        elif index<32000:\n",
    "            image_list = find_companions(data['image'], coco_image, 5)\n",
    "        elif index<36410:\n",
    "            image_list = find_companions(data['image'], coco_image, 8)\n",
    "        image_list.append(data['image'])\n",
    "        random.shuffle(image_list)\n",
    "        image_index = image_list.index(data['image'])\n",
    "        new_image_list = []\n",
    "        for img_path in image_list:\n",
    "            new_image_list.append('/mnt/petrelfs/liuziyu/V3Det/LLaVA/scripts/v1_5/data/cl_data/' + img_path)\n",
    "        output_path = f'/mnt/hwfile/mllm/liuziyu/RLHF_data/RLHF_combined_pics_v3/coco_{index}.jpg'\n",
    "        combine_images_with_labels(new_image_list, output_path)\n",
    "    \n",
    "        image_index += 1\n",
    "        image_length = len(image_list)\n",
    "        data['image'] = image_list\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "        for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "            if convs['from'] == 'human':\n",
    "                if convs_index == 0:\n",
    "                    convs['value'] = '<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                else:\n",
    "                    convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "        data['image'] = output_path\n",
    "        data[\"image_list\"] = new_image_list\n",
    "        mix_coco_data.append(data)\n",
    "        \n",
    "print(len(mix_coco_data))\n",
    "output_json_path = \"./mix_coco_data.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(mix_coco_data, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33fc3e56-0f4f-4767-8c1f-28c13f0f990c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31565\n",
      "7214\n",
      "8000\n",
      "2195\n",
      "48974\n",
      "Data has been written to ./ping_llava62k_dpo_v3.json\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/dpo_data_scripts/mix_coco_data.json\", 'r', encoding='utf-8') as file:\n",
    "    mix_coco_data = json.load(file)\n",
    "print(len(mix_coco_data))\n",
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/dpo_data_scripts/mix_gqa_data.json\", 'r', encoding='utf-8') as file:\n",
    "    mix_gqa_data = json.load(file)\n",
    "print(len(mix_gqa_data))\n",
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/dpo_data_scripts/mix_ocr_vqa_data.json\", 'r', encoding='utf-8') as file:\n",
    "    mix_ocr_vqa_data = json.load(file)\n",
    "print(len(mix_ocr_vqa_data))\n",
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/dpo_data_scripts/mix_textvqa_data.json\", 'r', encoding='utf-8') as file:\n",
    "    mix_textvqa_data = json.load(file)\n",
    "print(len(mix_textvqa_data))\n",
    "ping_llava62k_v2 = mix_coco_data+mix_gqa_data+mix_ocr_vqa_data+mix_textvqa_data\n",
    "print(len(ping_llava62k_v2))\n",
    "output_json_path = \"./ping_llava62k_dpo_v3.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(ping_llava62k_v2, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151bcd09-62df-4172-87b9-5c2a8e52d15c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
