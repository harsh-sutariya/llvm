{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b04b889c-efba-46b7-8278-15ed7cb2e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f51337-fa20-4f5b-889e-444a732f1f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187383\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/sft_data/llava187k.json\", 'r', encoding='utf-8') as file:\n",
    "    dpo_data = json.load(file)\n",
    "print(len(dpo_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07e954d-d488-44b4-80d3-7edbb5fb54d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '000000178859',\n",
       " 'image': 'coco/train2017/000000178859.jpg',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nWhat type of animals are in the image?'},\n",
       "  {'from': 'gpt', 'value': 'There are horses in the image.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'What is the terrain like where the horses are standing?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'The horses are standing in a grassy area beside a small rock wall.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Are the horses near any body of water or mountains?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Yes, the horses are in a rock-walled pasture by a lake in the mountains.'},\n",
       "  {'from': 'human', 'value': 'How many horses are visible in the image?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'There are a couple of horses visible in the image.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'What could be the purpose of the rock wall near the horses?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': \"The rock wall near the horses may serve a few purposes. One possible purpose is to act as a boundary or enclosure to keep the horses confined within the pasture area, ensuring they don't wander too far and can be easily managed by their owners. The wall can also provide some protection from predators and mark the division between different areas of the terrain.\\n\\nAnother reason for the presence of the wall could be historical or cultural. In many rural settings, stone walls were traditionally built to divide land for farming or livestock purposes. Over time, these walls may continue to be maintained or restored as part of the area's history or heritage, adding character to the landscape.\\n\\nLastly, the rock wall might be a natural feature of the environment or built for erosion control, particularly if the pasture is close to the lake or in a mountainous area with potential for land degradation. In this case, it would help maintain the integrity of the surrounding terrain and prevent soil erosion, preserving the pasture for the horses to graze in.\"}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_data[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a16ba2a-6f11-4c94-9940-4e2d755b0ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2195\n",
      "2195\n",
      "2195\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "textvqa 数据集全部都是以 <image>\\nProvide a one-sentence caption for the provided image.\\n 作为问题的开头\n",
    "\"\"\"\n",
    "count = 0\n",
    "count_convs = 0\n",
    "textvqa_data = []\n",
    "for data in dpo_data:\n",
    "    if data[\"image\"].split('/')[0] == 'textvqa':\n",
    "        textvqa_data.append(data)\n",
    "        if data[\"conversations\"][0]['value'].startswith('<image>\\n'):\n",
    "            count+=1\n",
    "        if len(data[\"conversations\"])==2:\n",
    "            count_convs += 1\n",
    "print(count)\n",
    "print(count_convs)\n",
    "print(len(textvqa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d8fe53-23c0-49a3-93e9-57192857b11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36410\n",
      "36410\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "coco 数据集全部都是以 <image>\\n 或者是 <image> 作为问题的开头或者是结尾\n",
    "\"\"\"\n",
    "count = 0\n",
    "coco_data = []\n",
    "for data in dpo_data:\n",
    "    if data[\"image\"].split('/')[0] == 'coco':\n",
    "        coco_data.append(data)\n",
    "        if data[\"conversations\"][0]['value'].startswith('<image>\\n'):\n",
    "            count+=1\n",
    "        if data[\"conversations\"][0]['value'].endswith('<image>'):\n",
    "            count+=1\n",
    "print(count)\n",
    "print(len(coco_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e99b868-cc0b-4509-8c74-3d67a8bde9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ocr_vqa 全部都是以 <image>\\n 作为问题的开头\n",
    "\"\"\"\n",
    "count = 0\n",
    "ocr_vqa_data = []\n",
    "for data in dpo_data:\n",
    "    if data[\"image\"].split('/')[0] == 'ocr_vqa':\n",
    "        ocr_vqa_data.append(data)\n",
    "        if data[\"conversations\"][0]['value'].startswith('<image>\\n'):\n",
    "            count+=1\n",
    "print(count)\n",
    "print(len(ocr_vqa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccdeaa58-8eaa-4990-bc9f-6c79dd5bffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8642\n",
      "8642\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "vg 全部都是以 <image>\\n 作为问题的开头\n",
    "\"\"\"\n",
    "count = 0\n",
    "vg_data = []\n",
    "for data in dpo_data:\n",
    "    if data[\"image\"].split('/')[0] == 'vg':\n",
    "        vg_data.append(data)\n",
    "        if data[\"conversations\"][0]['value'].startswith('<image>\\n'):\n",
    "            count+=1\n",
    "print(count)\n",
    "print(len(vg_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed22bc30-d022-402d-a196-2a5f715aaa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7214\n",
      "7214\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gpa 全部都是以 <image>\\n 作为问题的开头\n",
    "\"\"\"\n",
    "count = 0\n",
    "statistic = 0\n",
    "gqa_data = []\n",
    "for data in dpo_data:\n",
    "    if data[\"image\"].split('/')[0] == 'gqa':\n",
    "        gqa_data.append(data)\n",
    "        if data[\"conversations\"][0]['value'].startswith('<image>\\n') and data[\"conversations\"][0]['value'].endswith('Answer the question using a single word or phrase.'):\n",
    "            count+=1\n",
    "print(count)\n",
    "print(len(gqa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d6039-87c2-4b77-849b-5575da371b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ce635-85cc-433f-a0bd-742c9d87dac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227c9bb-3c33-44e6-b01c-ce11c8b63be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c6c801-dfb0-4da8-9374-b27d96ae8837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f80709-2a2f-4112-9eaf-1a604589478e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a6d71-7fd4-49d1-bb5f-686d0d8fc783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0906bc55-a020-4164-ac38-4f2f640eee35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da86d7a-9232-4aef-8a1e-49927827ec32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be59377-df4b-4095-bb23-e33370b06d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a128b1f5-81b9-4c8d-be59-506f184df06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "构造 textvqa + coco 45k的数据集\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23e077c9-d742-46a2-8c92-410af812c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_companions(input_str, str_list, count=1):\n",
    "    filtered_list = [s for s in str_list if s != input_str]\n",
    "    return random.sample(filtered_list, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e23e36-69ab-4128-ba7a-d3a2fb019c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "textvqa_image = []\n",
    "for data in dpo_data[:20000]:\n",
    "    textvqa_image.append(data[\"image\"])\n",
    "print(len(textvqa_image))\n",
    "\n",
    "coco_image = []\n",
    "for data in dpo_data[20000:]:\n",
    "    coco_image.append(data[\"image\"])\n",
    "print(len(coco_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83adf447-4c6c-4cc7-a993-bc942a02e435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存到 ./mix_testvqa_20k.json\n"
     ]
    }
   ],
   "source": [
    "mix_data = []\n",
    "for index, data in enumerate(dpo_data[:20000]):\n",
    "    if index<11000:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 1)\n",
    "    elif index<14000:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 2)\n",
    "    elif index<17000:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 3)\n",
    "    elif index<20000:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 4)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    if image_length == 2:\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', 'Image1:<image>\\nImage2:<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    if image_length == 3:\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    if image_length == 4:\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    if image_length == 5:\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\nImage5:<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    mix_data.append(data)\n",
    "    \n",
    "file_path = \"./mix_testvqa_20k.json\"\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(mix_data, file, indent=4)\n",
    "print(f'数据已保存到 {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea482e33-9970-4429-9144-0f28cd79c1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存到 ./mix_coco_25k.json\n"
     ]
    }
   ],
   "source": [
    "mix_data = []\n",
    "for index, data in enumerate(dpo_data[20000:]):\n",
    "    if index<16000:\n",
    "        image_list = find_companions(data['image'], coco_image, 1)\n",
    "    elif index<19000:\n",
    "        image_list = find_companions(data['image'], coco_image, 2)\n",
    "    elif index<22000:\n",
    "        image_list = find_companions(data['image'], coco_image, 3)\n",
    "    elif index<25000:\n",
    "        image_list = find_companions(data['image'], coco_image, 4)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                if image_length == 2:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 3:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 4:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 5:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\nImage5:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    mix_data.append(data)\n",
    "    \n",
    "file_path = \"./mix_coco_25k.json\"\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(mix_data, file, indent=4)\n",
    "print(f'数据已保存到 {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "840d78a3-a854-4645-acfa-4fab790f3876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def merge_json_files(file_path1, file_path2, output_file_path):\n",
    "    # 读取第一个JSON文件\n",
    "    with open(file_path1, 'r') as file:\n",
    "        data1 = json.load(file)\n",
    "    \n",
    "    # 读取第二个JSON文件\n",
    "    with open(file_path2, 'r') as file:\n",
    "        data2 = json.load(file)\n",
    "    \n",
    "    # 合并两个字典\n",
    "    merged_list = data1 + data2  # 列表拼接\n",
    "    \n",
    "    # 将合并后的数据写入新的JSON文件\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        json.dump(merged_list, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5af9b472-80a7-4386-bf14-f6966ed207db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON文件路径\n",
    "file_path1 = './mix_testvqa_20k.json'\n",
    "file_path2 = './mix_coco_25k.json'\n",
    "output_file_path = './mix_textvqa_20k_coco_25k.json'\n",
    "\n",
    "# 调用函数合并文件\n",
    "merge_json_files(file_path1, file_path2, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0abb7f3-bf06-421f-8859-26fe93d76898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON文件路径\n",
    "file_path1 = './mix_textvqa_20k_coco_25k.json'\n",
    "file_path2 = '/mnt/hwfile/mllm/chenlin/llava/data/llava/llava_v1_5_mix665k.json'\n",
    "output_file_path = './llava_all665k_textvqa_20k_coco_25k.json'\n",
    "\n",
    "# 调用函数合并文件\n",
    "merge_json_files(file_path1, file_path2, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b84a95-1f1f-407a-afd8-83bb5faa0f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91869df-1f01-4cfd-8838-8401ab4d0380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc09bc8-593a-4878-9bed-710398f4b390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f164b-2707-4383-be01-df68d8349649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5cc27-991e-4ee5-ad4c-8467405dba3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b10758-49c7-4c1a-a642-94b03a74f9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c5816-82a5-488c-9aa9-57a68f729c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a204d4d-c615-489e-9f5d-10142b82aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "变动 textvqa 和 coco 数据集的数据组合比例\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402dcfb5-0b99-4269-8567-e095204139f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/mix_textvqa_20k_coco_25k.json\", 'r', encoding='utf-8') as file:\n",
    "    dpo_data = json.load(file)\n",
    "print(len(dpo_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6eb32f6-5e4d-4413-b338-53b1aa4a832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    }
   ],
   "source": [
    "mix_textvqa_20k_coco_20k = dpo_data[:40000]\n",
    "print(len(mix_textvqa_20k_coco_20k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68d46773-18c2-4ac0-8c09-d8d8e5020a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./mix_textvqa_20k_coco_20k.json\"\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(mix_textvqa_20k_coco_20k, file, indent=4)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710f281-8476-4913-9bec-79113bd42de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "变动数据比例\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0df336c1-4fe9-4dc0-81b6-888ed3e2521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/mix_textvqa_20k_coco_25k.json\", 'r', encoding='utf-8') as file:\n",
    "    dpo_data = json.load(file)\n",
    "print(len(dpo_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df5106dd-d5a1-4ede-9bae-f16fcfb6c673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    }
   ],
   "source": [
    "mix_textvqa_15k_coco_25k = dpo_data[5000:]\n",
    "print(len(mix_textvqa_15k_coco_25k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f437ba43-b3fa-4c5b-a5aa-6dbd5998a47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./mix_textvqa_15k_coco_25k.json\"\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(mix_textvqa_15k_coco_25k, file, indent=4)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee223c-4f94-4deb-94b2-6854f6637708",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "变动数据比例\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16f325ec-df1d-45f9-aa9d-7912e2388015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/mix_textvqa_20k_coco_25k.json\", 'r', encoding='utf-8') as file:\n",
    "    dpo_data = json.load(file)\n",
    "print(len(dpo_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5090f603-8b82-480a-9f49-112b332574d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39000\n"
     ]
    }
   ],
   "source": [
    "mix_textvqa_17k_coco_22k = dpo_data[3000:42000]\n",
    "print(len(mix_textvqa_17k_coco_22k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cdf4754-3cdb-42eb-b907-98b8fc70ee5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./mix_textvqa_17k_coco_22k.json\"\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(mix_textvqa_17k_coco_22k, file, indent=4)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaeb0de-519c-4f24-81cf-036fbd2979f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c732dbb-2849-41f1-98ee-70c68bb86163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587210b4-a688-42c6-b561-17905b63fa26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39ee61-9bce-4e61-ad0e-87838f47a2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2b4d96-e2f0-4c70-b5f3-23a4e66f313f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712dfe1-eb6d-4121-a4aa-66742c20fefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389a90c-cd12-42a6-bdbb-db027bd46645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917c4c5f-fe7f-4ce0-9a64-2a975f6779b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d6815-862c-44d8-b5d5-392e5821233e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde388d2-778f-469e-98ff-c65e54005c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "从 llava665k 中选取了 62k 的数据，并组合为多图数据\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99a81e94-67da-4846-be1e-e7dbea43a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_companions(input_str, str_list, count=1):\n",
    "    filtered_list = [s for s in str_list if s != input_str]\n",
    "    return random.sample(filtered_list, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "071a014c-34e5-4aae-bc8a-842be88680f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2195\n",
      "36410\n",
      "8000\n",
      "8642\n",
      "7214\n",
      "62461\n"
     ]
    }
   ],
   "source": [
    "textvqa_image = []\n",
    "for data in textvqa_data:\n",
    "    textvqa_image.append(data[\"image\"])\n",
    "print(len(textvqa_image))\n",
    "\n",
    "coco_image = []\n",
    "for data in coco_data:\n",
    "    coco_image.append(data[\"image\"])\n",
    "print(len(coco_image))\n",
    "\n",
    "ocr_vqa_image = []\n",
    "for data in ocr_vqa_data:\n",
    "    ocr_vqa_image.append(data[\"image\"])\n",
    "print(len(ocr_vqa_image))\n",
    "\n",
    "vq_image = []\n",
    "for data in vg_data:\n",
    "    vq_image.append(data[\"image\"])\n",
    "print(len(vq_image))\n",
    "\n",
    "gqa_image = []\n",
    "for data in gqa_data:\n",
    "    gqa_image.append(data[\"image\"])\n",
    "print(len(gqa_image))\n",
    "\n",
    "all_images = textvqa_image + coco_image + ocr_vqa_image + vq_image + gqa_image\n",
    "print(len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2bdae40-6471-4f37-95f7-c7ab808d2927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2195\n"
     ]
    }
   ],
   "source": [
    "mix_textvqa_data = []\n",
    "for index, data in enumerate(textvqa_data):\n",
    "    if index<1200:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 1)\n",
    "    elif index<1550:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 2)\n",
    "    elif index<1900:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 3)\n",
    "    elif index<2195:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 4)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    if image_length == 2:\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', 'Image1:<image>\\nImage2:<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    if image_length == 3:\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    if image_length == 4:\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    if image_length == 5:\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\nImage5:<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    mix_textvqa_data.append(data)\n",
    "\n",
    "print(len(mix_textvqa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "999122eb-49cc-42fd-b971-fc72d767e25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36410\n"
     ]
    }
   ],
   "source": [
    "mix_coco_data = []\n",
    "for index, data in enumerate(coco_data):\n",
    "    if index<20000:\n",
    "        image_list = find_companions(data['image'], coco_image, 1)\n",
    "    elif index<26000:\n",
    "        image_list = find_companions(data['image'], coco_image, 2)\n",
    "    elif index<32000:\n",
    "        image_list = find_companions(data['image'], coco_image, 3)\n",
    "    elif index<36410:\n",
    "        image_list = find_companions(data['image'], coco_image, 4)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                if image_length == 2:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 3:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 4:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 5:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\nImage5:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    mix_coco_data.append(data)\n",
    "print(len(mix_coco_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e1c8605-59da-42eb-8f36-3f96ac628def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "mix_ocr_vqa_data = []\n",
    "for index, data in enumerate(ocr_vqa_data):\n",
    "    if index<4500:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 1)\n",
    "    elif index<5700:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 2)\n",
    "    elif index<6900:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 3)\n",
    "    elif index<8000:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 4)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                if image_length == 2:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 3:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 4:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 5:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\nImage5:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    mix_ocr_vqa_data.append(data)\n",
    "print(len(mix_ocr_vqa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc414751-b9c6-4500-82cf-e448800975ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8642\n"
     ]
    }
   ],
   "source": [
    "mix_vg_data = []\n",
    "for index, data in enumerate(vg_data):\n",
    "    if index<4800:\n",
    "        image_list = find_companions(data['image'], vq_image, 1)\n",
    "    elif index<6100:\n",
    "        image_list = find_companions(data['image'], vq_image, 2)\n",
    "    elif index<7400:\n",
    "        image_list = find_companions(data['image'], vq_image, 3)\n",
    "    elif index<8642:\n",
    "        image_list = find_companions(data['image'], vq_image, 4)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                if image_length == 2:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 3:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 4:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 5:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\nImage5:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    mix_vg_data.append(data)\n",
    "print(len(mix_vg_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc4faac4-9c67-4793-bc3d-c32c1036ee1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7214\n"
     ]
    }
   ],
   "source": [
    "mix_gqa_data = []\n",
    "for index, data in enumerate(gqa_data):\n",
    "    if index<3800:\n",
    "        image_list = find_companions(data['image'], gqa_image, 1)\n",
    "    elif index<5000:\n",
    "        image_list = find_companions(data['image'], gqa_image, 2)\n",
    "    elif index<6100:\n",
    "        image_list = find_companions(data['image'], gqa_image, 3)\n",
    "    elif index<7214:\n",
    "        image_list = find_companions(data['image'], gqa_image, 4)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                if image_length == 2:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 3:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 4:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 5:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\nImage5:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    mix_gqa_data.append(data)\n",
    "print(len(mix_gqa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a48b0ec-8866-47bb-81a0-77cc9acba9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62461\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "mix_data = mix_textvqa_data + mix_coco_data + mix_ocr_vqa_data + mix_vg_data + mix_gqa_data\n",
    "print(len(mix_data))\n",
    "file_path = \"./mix_llava62k_dpo_v2.json\"\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(mix_data, file, indent=4)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47b71f-f2c4-428d-90b7-c1c57e48dc0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a2c963-2d8f-432e-9d8c-ec2bff56117e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb60515-6c34-419a-a4ad-2b79bb60a735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642d942-7a6b-48ac-9173-a2a48d43c936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f25bb9-ef28-418e-84aa-b8ae1728cfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8010af1d-e442-4c76-8c32-dcf6c0a9620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "从 llava665k 中选取了 62k 的数据，并组合拼图数据\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6f0ea40-718b-480d-a7f9-bcc35b0b2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_companions(input_str, str_list, count=1):\n",
    "    filtered_list = [s for s in str_list if s != input_str]\n",
    "    return random.sample(filtered_list, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d17cf5a0-4f39-416a-9655-c2f466d0e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def resize_and_pad(image, target_size):\n",
    "    \"\"\"Resize and pad an image to the target size.\"\"\"\n",
    "    img_ratio = image.width / image.height\n",
    "    target_ratio = target_size[0] / target_size[1]\n",
    "\n",
    "    if img_ratio > target_ratio:\n",
    "        new_width = target_size[0]\n",
    "        new_height = int(new_width / img_ratio)\n",
    "    else:\n",
    "        new_height = target_size[1]\n",
    "        new_width = int(new_height * img_ratio)\n",
    "\n",
    "    resized_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    new_image = Image.new(\"RGB\", target_size, (255, 255, 255))\n",
    "    # paste_x = (target_size[0] - new_width) // 2\n",
    "    # paste_y = (target_size[1] - new_height) // 2\n",
    "    paste_x = 0\n",
    "    paste_y = 0\n",
    "    new_image.paste(resized_image, (paste_x, paste_y))\n",
    "    return new_image\n",
    "\n",
    "def combine_images_with_labels(image_paths, output_path, target_size=(448, 448), margin=40):\n",
    "    # # 获取提问的图像的大小\n",
    "    # resize_size = Image.open(image_paths[image_index-1]).size\n",
    "    # print(resize_size)\n",
    "    # # Load images and resize them\n",
    "    # images = [Image.open(image_path).resize(resize_size) for image_path in image_paths]\n",
    "    # num_images = len(images)\n",
    "\n",
    "    images = [resize_and_pad(Image.open(image_path), target_size) for image_path in image_paths]\n",
    "    num_images = len(images)\n",
    "\n",
    "    resize_size = target_size\n",
    "    # Calculate combined image size\n",
    "    if num_images == 2 or num_images == 3:\n",
    "        combined_width = resize_size[0] * num_images + margin * (num_images - 1)\n",
    "        combined_height = resize_size[1] + margin  # Add margin for labels\n",
    "    elif num_images == 4:\n",
    "        combined_width = resize_size[0] * 2 + margin\n",
    "        combined_height = resize_size[1] * 2 + margin * 2  # Add margin for labels\n",
    "    elif num_images == 6:\n",
    "        combined_width = resize_size[0] * 3 + margin * 2\n",
    "        combined_height = resize_size[1] * 2 + margin * 2  # Add margin for labels\n",
    "    elif num_images == 9:\n",
    "        combined_width = resize_size[0] * 3 + margin * 2\n",
    "        combined_height = resize_size[1] * 3 + margin * 3  # Add margin for labels\n",
    "    else:\n",
    "        raise ValueError(\"The number of images must be 2, 3, 4, 6, or 9.\")\n",
    "    \n",
    "    # Create new image with white background\n",
    "    combined_image = Image.new('RGB', (combined_width, combined_height), (255, 255, 255))\n",
    "    \n",
    "    # Define positions for each image and label\n",
    "    positions = []\n",
    "    labels = []\n",
    "    if num_images == 2 or num_images == 3:\n",
    "        for i in range(num_images):\n",
    "            x = i * (resize_size[0] + margin)\n",
    "            y = 0+margin\n",
    "            positions.append((x, y))\n",
    "            labels.append(f\"Image{i+1}\")\n",
    "    elif num_images == 4:\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                x = j * (resize_size[0] + margin)\n",
    "                y = i * (resize_size[1] + margin)+margin\n",
    "                positions.append((x, y))\n",
    "                labels.append(f\"Image{2*i+j+1}\")\n",
    "    elif num_images == 6:\n",
    "        for i in range(2):\n",
    "            for j in range(3):\n",
    "                x = j * (resize_size[0] + margin)\n",
    "                y = i * (resize_size[1] + margin)+margin\n",
    "                positions.append((x, y))\n",
    "                labels.append(f\"Image{3*i+j+1}\")\n",
    "    elif num_images == 9:\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                x = j * (resize_size[0] + margin)\n",
    "                y = i * (resize_size[1] + margin)+margin\n",
    "                positions.append((x, y))\n",
    "                labels.append(f\"Image{3*i+j+1}\")\n",
    "    \n",
    "    # Paste images and draw labels\n",
    "    draw = ImageDraw.Draw(combined_image)\n",
    "    font = ImageFont.truetype(\"Arial.ttf\", 36)  # Load a larger TrueType font, or use another available font\n",
    "\n",
    "    for img, pos, label in zip(images, positions, labels):\n",
    "        combined_image.paste(img, pos)\n",
    "        # Calculate label position in the left top corner\n",
    "        label_x = pos[0] + 20  # Add some padding from the left edge\n",
    "        label_y = pos[1] - 40  # Add some padding from the top edge\n",
    "        draw.text((label_x, label_y), label, (0, 0, 0), font=font)\n",
    "    \n",
    "    # Save the combined image\n",
    "    combined_image.save(output_path)\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# image_list = [\n",
    "#     \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/car1.jpg\",\n",
    "#     \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/car2.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/newcar3.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/newcar4.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/apple.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/bear.png\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/apple.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/apple.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/apple.jpg\",\n",
    "# ]\n",
    "# output_path = \"./combined_image_9.png\"\n",
    "# combine_images_with_labels(image_list, output_path)\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a56c34d-5740-406d-86aa-135b2b9a5e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2195\n",
      "36410\n",
      "8000\n",
      "8642\n",
      "7214\n",
      "62461\n"
     ]
    }
   ],
   "source": [
    "textvqa_image = []\n",
    "for data in textvqa_data:\n",
    "    textvqa_image.append(data[\"image\"])\n",
    "print(len(textvqa_image))\n",
    "\n",
    "coco_image = []\n",
    "for data in coco_data:\n",
    "    coco_image.append(data[\"image\"])\n",
    "print(len(coco_image))\n",
    "\n",
    "ocr_vqa_image = []\n",
    "for data in ocr_vqa_data:\n",
    "    ocr_vqa_image.append(data[\"image\"])\n",
    "print(len(ocr_vqa_image))\n",
    "\n",
    "vq_image = []\n",
    "for data in vg_data:\n",
    "    vq_image.append(data[\"image\"])\n",
    "print(len(vq_image))\n",
    "\n",
    "gqa_image = []\n",
    "for data in gqa_data:\n",
    "    gqa_image.append(data[\"image\"])\n",
    "print(len(gqa_image))\n",
    "\n",
    "all_images = textvqa_image + coco_image + ocr_vqa_image + vq_image + gqa_image\n",
    "print(len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d19cb04-04e0-40ab-9af2-9cf08b863850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2195it [02:59, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2195\n",
      "Data has been written to ./mix_textvqa_data.json\n"
     ]
    }
   ],
   "source": [
    "mix_textvqa_data = []\n",
    "for index, data in tqdm(enumerate(textvqa_data)):\n",
    "    if index<1000:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 1)\n",
    "    elif index<1300:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 2)\n",
    "    elif index<1600:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 3)\n",
    "    elif index<1900:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 5)\n",
    "    elif index<2195:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 8)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "    new_image_list = []\n",
    "    for img_path in image_list:\n",
    "        new_image_list.append('/mnt/petrelfs/liuziyu/V3Det/LLaVA/scripts/v1_5/data/cl_data/' + img_path)\n",
    "    output_path = f'/mnt/hwfile/mllm/liuziyu/RLHF_data/RLHF_combined_pics_v2/textvqa_{index}.jpg'\n",
    "    combine_images_with_labels(new_image_list, output_path)\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', '<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    data['image'] = output_path\n",
    "    mix_textvqa_data.append(data)\n",
    "\n",
    "print(len(mix_textvqa_data))\n",
    "output_json_path = \"./mix_textvqa_data.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(mix_textvqa_data, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5ac39b3-c094-4bea-b51e-86e57b2920d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [05:18, 25.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "Data has been written to ./mix_ocr_vqa_data.json\n"
     ]
    }
   ],
   "source": [
    "mix_ocr_vqa_data = []\n",
    "for index, data in tqdm(enumerate(ocr_vqa_data)):\n",
    "    if index<3800:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 1)\n",
    "    elif index<4900:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 2)\n",
    "    elif index<6000:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 3)\n",
    "    elif index<7100:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 5)\n",
    "    elif index<8000:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 8)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "    new_image_list = []\n",
    "    for img_path in image_list:\n",
    "        new_image_list.append('/mnt/petrelfs/liuziyu/V3Det/LLaVA/scripts/v1_5/data/cl_data/' + img_path)\n",
    "    output_path = f'/mnt/hwfile/mllm/liuziyu/RLHF_data/RLHF_combined_pics_v2/ocrvqa_{index}.jpg'\n",
    "    combine_images_with_labels(new_image_list, output_path)\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                convs['value'] = '<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    data['image'] = output_path\n",
    "    mix_ocr_vqa_data.append(data)\n",
    "    \n",
    "print(len(mix_ocr_vqa_data))\n",
    "output_json_path = \"./mix_ocr_vqa_data.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(mix_ocr_vqa_data, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62cbd2cf-da64-4b1e-af47-497d859debeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7214it [05:35, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7214\n",
      "Data has been written to ./mix_gqa_data.json\n"
     ]
    }
   ],
   "source": [
    "mix_gqa_data = []\n",
    "for index, data in tqdm(enumerate(gqa_data)):\n",
    "    if index<3200:\n",
    "        image_list = find_companions(data['image'], gqa_image, 1)\n",
    "    elif index<4300:\n",
    "        image_list = find_companions(data['image'], gqa_image, 2)\n",
    "    elif index<5400:\n",
    "        image_list = find_companions(data['image'], gqa_image, 3)\n",
    "    elif index<6300:\n",
    "        image_list = find_companions(data['image'], gqa_image, 5)\n",
    "    elif index<7214:\n",
    "        image_list = find_companions(data['image'], gqa_image, 8)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "    new_image_list = []\n",
    "    for img_path in image_list:\n",
    "        new_image_list.append('/mnt/petrelfs/liuziyu/V3Det/LLaVA/scripts/v1_5/data/cl_data/' + img_path)\n",
    "    output_path = f'/mnt/hwfile/mllm/liuziyu/RLHF_data/RLHF_combined_pics_v2/gqa_{index}.jpg'\n",
    "    combine_images_with_labels(new_image_list, output_path)\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                convs['value'] = '<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    data['image'] = output_path\n",
    "    mix_gqa_data.append(data)\n",
    "    \n",
    "print(len(mix_gqa_data))\n",
    "output_json_path = \"./mix_gqa_data.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(mix_gqa_data, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be658223-fa62-4e82-acd7-8d9cd1a2f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def contains_bbox(s):\n",
    "    bbox_pattern = r'\\[\\s*\\d+(\\.\\d+)?,\\s*\\d+(\\.\\d+)?,\\s*\\d+(\\.\\d+)?,\\s*\\d+(\\.\\d+)?\\s*\\]'\n",
    "    match = re.search(bbox_pattern, s)\n",
    "    if match:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ff68d69-3459-495b-ba42-711dc24c5895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36410it [22:36, 26.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31565\n",
      "Data has been written to ./mix_coco_data.json\n"
     ]
    }
   ],
   "source": [
    "mix_coco_data = []\n",
    "for index, data in tqdm(enumerate(coco_data)):\n",
    "    choose_flase = True\n",
    "    for conv in data[\"conversations\"]:\n",
    "        conv_value = conv[\"value\"]\n",
    "        if contains_bbox(conv_value):\n",
    "            choose_flase = False\n",
    "    if choose_flase == True: \n",
    "        if index<18000:\n",
    "            image_list = find_companions(data['image'], coco_image, 1)\n",
    "        elif index<23000:\n",
    "            image_list = find_companions(data['image'], coco_image, 2)\n",
    "        elif index<28000:\n",
    "            image_list = find_companions(data['image'], coco_image, 3)\n",
    "        elif index<32000:\n",
    "            image_list = find_companions(data['image'], coco_image, 5)\n",
    "        elif index<36410:\n",
    "            image_list = find_companions(data['image'], coco_image, 8)\n",
    "        image_list.append(data['image'])\n",
    "        random.shuffle(image_list)\n",
    "        image_index = image_list.index(data['image'])\n",
    "        new_image_list = []\n",
    "        for img_path in image_list:\n",
    "            new_image_list.append('/mnt/petrelfs/liuziyu/V3Det/LLaVA/scripts/v1_5/data/cl_data/' + img_path)\n",
    "        output_path = f'/mnt/hwfile/mllm/liuziyu/RLHF_data/RLHF_combined_pics_v2/coco_{index}.jpg'\n",
    "        combine_images_with_labels(new_image_list, output_path)\n",
    "    \n",
    "        image_index += 1\n",
    "        image_length = len(image_list)\n",
    "        data['image'] = image_list\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "        for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "            if convs['from'] == 'human':\n",
    "                if convs_index == 0:\n",
    "                    convs['value'] = '<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                else:\n",
    "                    convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "        data['image'] = output_path\n",
    "        mix_coco_data.append(data)\n",
    "        \n",
    "print(len(mix_coco_data))\n",
    "output_json_path = \"./mix_coco_data.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(mix_coco_data, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56a3ad26-f8c5-4c90-9447-4bf36cc4a328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31565\n",
      "7214\n",
      "8000\n",
      "2195\n",
      "48974\n",
      "Data has been written to ./ping_llava62k_dpo_v3.json\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/mix_coco_data.json\", 'r', encoding='utf-8') as file:\n",
    "    mix_coco_data = json.load(file)\n",
    "print(len(mix_coco_data))\n",
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/mix_gqa_data.json\", 'r', encoding='utf-8') as file:\n",
    "    mix_gqa_data = json.load(file)\n",
    "print(len(mix_gqa_data))\n",
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/mix_ocr_vqa_data.json\", 'r', encoding='utf-8') as file:\n",
    "    mix_ocr_vqa_data = json.load(file)\n",
    "print(len(mix_ocr_vqa_data))\n",
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/mix_textvqa_data.json\", 'r', encoding='utf-8') as file:\n",
    "    mix_textvqa_data = json.load(file)\n",
    "print(len(mix_textvqa_data))\n",
    "ping_llava62k_v2 = mix_coco_data+mix_gqa_data+mix_ocr_vqa_data+mix_textvqa_data\n",
    "print(len(ping_llava62k_v2))\n",
    "output_json_path = \"./ping_llava62k_dpo_v3.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(ping_llava62k_v2, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e9726b-f4c9-42d1-bdb6-effb4d31109a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3214e-be7a-48a8-b92e-889673d11cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4234fb-4e7a-46a9-b5ed-a4de82070a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb74b3bb-6bf7-4d00-87d6-67b8e3993e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47883ac-dd99-4f82-9a26-644610eb6bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce77906-c361-4afe-a96a-54d6d75c0463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e94e80-ec23-42c0-961a-959dda1115a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00645857-18a7-4bad-9e2f-857773396f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9d120-98d5-4862-8fa3-917f9ba794c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "从 llava665k 中选取了 62k 的数据，抽取50分之一，构造拒答数据\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52874d0b-003d-4c27-8d76-e043c8cf71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_companions(input_str, str_list, count=1):\n",
    "    filtered_list = [s for s in str_list if s != input_str]\n",
    "    return random.sample(filtered_list, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04375807-b639-48c2-b673-dcece403faa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2195\n",
      "36410\n",
      "8000\n",
      "8642\n",
      "7214\n",
      "62461\n"
     ]
    }
   ],
   "source": [
    "textvqa_image = []\n",
    "for data in textvqa_data:\n",
    "    textvqa_image.append(data[\"image\"])\n",
    "print(len(textvqa_image))\n",
    "\n",
    "coco_image = []\n",
    "for data in coco_data:\n",
    "    coco_image.append(data[\"image\"])\n",
    "print(len(coco_image))\n",
    "\n",
    "ocr_vqa_image = []\n",
    "for data in ocr_vqa_data:\n",
    "    ocr_vqa_image.append(data[\"image\"])\n",
    "print(len(ocr_vqa_image))\n",
    "\n",
    "vq_image = []\n",
    "for data in vg_data:\n",
    "    vq_image.append(data[\"image\"])\n",
    "print(len(vq_image))\n",
    "\n",
    "gqa_image = []\n",
    "for data in gqa_data:\n",
    "    gqa_image.append(data[\"image\"])\n",
    "print(len(gqa_image))\n",
    "\n",
    "all_images = textvqa_image + coco_image + ocr_vqa_image + vq_image + gqa_image\n",
    "print(len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "928b5d83-c235-4ce3-b296-af9251f8d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "mix_textvqa_data = []\n",
    "for index, data in enumerate(textvqa_data[::50]):\n",
    "    if index*50<1200:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 1)\n",
    "    elif index*50<1550:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 2)\n",
    "    elif index*50<1900:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 3)\n",
    "    elif index*50<2195:\n",
    "        image_list = find_companions(data['image'], textvqa_image, 4)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "\n",
    "    image_index = len(image_list)+1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    if image_length == 2:\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', 'Image1:<image>\\nImage2:<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    if image_length == 3:\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    if image_length == 4:\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    if image_length == 5:\n",
    "        data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\nProvide a one-sentence caption for the provided image.\\n', 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\nImage5:<image>\\n' + f'In Image{image_index}, provide a one-sentence caption for the provided image.\\n')\n",
    "    data[\"conversations\"][1]['value'] = f'You only provided {image_length} images, Image{image_index} does not exist.'\n",
    "    data[\"conversations\"] = data[\"conversations\"][:2]\n",
    "    mix_textvqa_data.append(data)\n",
    "\n",
    "print(len(mix_textvqa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34c07b97-e85c-4181-86ac-cf1a4596b195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729\n"
     ]
    }
   ],
   "source": [
    "mix_coco_data = []\n",
    "for index, data in enumerate(coco_data[::50]):\n",
    "    if index*50<20000:\n",
    "        image_list = find_companions(data['image'], coco_image, 1)\n",
    "    elif index*50<26000:\n",
    "        image_list = find_companions(data['image'], coco_image, 2)\n",
    "    elif index*50<32000:\n",
    "        image_list = find_companions(data['image'], coco_image, 3)\n",
    "    elif index*50<36410:\n",
    "        image_list = find_companions(data['image'], coco_image, 4)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "\n",
    "    image_index = len(image_list)+1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                if image_length == 2:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 3:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 4:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 5:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\nImage5:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    data[\"conversations\"][1]['value'] = f'You only provided {image_length} images, Image{image_index} does not exist.'\n",
    "    data[\"conversations\"] = data[\"conversations\"][:2]\n",
    "    mix_coco_data.append(data)\n",
    "print(len(mix_coco_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4df0a4bf-24e1-435e-b7cf-3f2986012bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "mix_ocr_vqa_data = []\n",
    "for index, data in enumerate(ocr_vqa_data[::50]):\n",
    "    if index*50<4500:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 1)\n",
    "    elif index*50<5700:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 2)\n",
    "    elif index*50<6900:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 3)\n",
    "    elif index*50<8000:\n",
    "        image_list = find_companions(data['image'], ocr_vqa_image, 4)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "\n",
    "    image_index = len(image_list)+1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                if image_length == 2:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 3:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 4:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 5:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\nImage5:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    data[\"conversations\"][1]['value'] = f'You only provided {image_length} images, Image{image_index} does not exist.'\n",
    "    data[\"conversations\"] = data[\"conversations\"][:2]\n",
    "    mix_ocr_vqa_data.append(data)\n",
    "print(len(mix_ocr_vqa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e78b8983-358a-4ec8-9b4e-756a8c78d8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n"
     ]
    }
   ],
   "source": [
    "mix_vg_data = []\n",
    "for index, data in enumerate(vg_data[::50]):\n",
    "    if index*50<4800:\n",
    "        image_list = find_companions(data['image'], vq_image, 1)\n",
    "    elif index*50<6100:\n",
    "        image_list = find_companions(data['image'], vq_image, 2)\n",
    "    elif index*50<7400:\n",
    "        image_list = find_companions(data['image'], vq_image, 3)\n",
    "    elif index*50<8642:\n",
    "        image_list = find_companions(data['image'], vq_image, 4)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "\n",
    "    image_index = len(image_list)+1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                if image_length == 2:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 3:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 4:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 5:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\nImage5:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    data[\"conversations\"][1]['value'] = f'You only provided {image_length} images, Image{image_index} does not exist.'\n",
    "    data[\"conversations\"] = data[\"conversations\"][:2]\n",
    "    mix_vg_data.append(data)\n",
    "print(len(mix_vg_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25195a6b-7b5b-4aa8-b804-525263b9329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "mix_gqa_data = []\n",
    "for index, data in enumerate(gqa_data[::50]):\n",
    "    if index*50<3800:\n",
    "        image_list = find_companions(data['image'], gqa_image, 1)\n",
    "    elif index*50<5000:\n",
    "        image_list = find_companions(data['image'], gqa_image, 2)\n",
    "    elif index*50<6100:\n",
    "        image_list = find_companions(data['image'], gqa_image, 3)\n",
    "    elif index*50<7214:\n",
    "        image_list = find_companions(data['image'], gqa_image, 4)\n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "\n",
    "    image_index = len(image_list)+1\n",
    "    image_length = len(image_list)\n",
    "    data['image'] = image_list\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                if image_length == 2:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 3:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 4:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                if image_length == 5:\n",
    "                    convs['value'] = 'Image1:<image>\\nImage2:<image>\\nImage3:<image>\\nImage4:<image>\\nImage5:<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    data[\"conversations\"][1]['value'] = f'You only provided {image_length} images, Image{image_index} does not exist.'\n",
    "    data[\"conversations\"] = data[\"conversations\"][:2]\n",
    "    mix_gqa_data.append(data)\n",
    "print(len(mix_gqa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4575307c-e478-4d09-83fc-81ea641034df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1251\n"
     ]
    }
   ],
   "source": [
    "mix_data = mix_textvqa_data + mix_coco_data + mix_ocr_vqa_data + mix_vg_data + mix_gqa_data\n",
    "print(len(mix_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1794faca-3892-4cdd-b4cd-b435dadc016a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./mix_llava62k_v3_reject_answer_1251.json\"\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(mix_data, file, indent=4)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e0ac6-4734-4e59-96c8-d190bf49875f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0480572-6dc2-4557-b5d3-0d826b159aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72204b-dd6b-42de-9d1c-3d9d44a5e308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c973e2-a463-446c-816b-26ef03b6f1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8687e8be-7ed3-48c5-b274-31d4915e619d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fcf169-178d-4a19-8c78-1b079fd9af9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6757b55a-ecc9-4b74-b7fc-b6a0b077c8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdbc039-a8de-491a-97eb-d177d9426186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "从 llava665k 中选取了 187k 的数据，并组合 多轮对话 拼图数据\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6f9b87-d467-42a7-b9cb-b627e51f0fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['banana', 'orange']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def find_companions(input_str, str_list, count=1):\n",
    "    if isinstance(input_str, list):\n",
    "        input_set = set(input_str)\n",
    "    else:\n",
    "        input_set = {input_str}\n",
    "    \n",
    "    filtered_set = set(str_list) - input_set\n",
    "    filtered_list = list(filtered_set)\n",
    "    \n",
    "    count = min(count, len(filtered_list))\n",
    "    \n",
    "    return random.sample(filtered_list, count)\n",
    "\n",
    "# 示例\n",
    "str_list = [\"apple\", \"banana\", \"orange\", \"grape\", \"melon\"]\n",
    "input_str = [\"apple\", \"grape\"]\n",
    "result = find_companions(input_str, str_list, count=2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a0dc49-f1c3-46ae-985e-78d3c20f923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def resize_and_pad(image, target_size):\n",
    "    \"\"\"Resize and pad an image to the target size.\"\"\"\n",
    "    img_ratio = image.width / image.height\n",
    "    target_ratio = target_size[0] / target_size[1]\n",
    "\n",
    "    if img_ratio > target_ratio:\n",
    "        new_width = target_size[0]\n",
    "        new_height = int(new_width / img_ratio)\n",
    "    else:\n",
    "        new_height = target_size[1]\n",
    "        new_width = int(new_height * img_ratio)\n",
    "\n",
    "    resized_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    new_image = Image.new(\"RGB\", target_size, (255, 255, 255))\n",
    "    # paste_x = (target_size[0] - new_width) // 2\n",
    "    # paste_y = (target_size[1] - new_height) // 2\n",
    "    paste_x = 0\n",
    "    paste_y = 0\n",
    "    new_image.paste(resized_image, (paste_x, paste_y))\n",
    "    return new_image\n",
    "\n",
    "def combine_images_with_labels(image_paths, output_path, target_size=(448, 448), margin=40):\n",
    "    # # 获取提问的图像的大小\n",
    "    # resize_size = Image.open(image_paths[image_index-1]).size\n",
    "    # print(resize_size)\n",
    "    # # Load images and resize them\n",
    "    # images = [Image.open(image_path).resize(resize_size) for image_path in image_paths]\n",
    "    # num_images = len(images)\n",
    "\n",
    "    images = [resize_and_pad(Image.open(image_path), target_size) for image_path in image_paths]\n",
    "    num_images = len(images)\n",
    "\n",
    "    resize_size = target_size\n",
    "    # Calculate combined image size\n",
    "    if num_images == 2 or num_images == 3:\n",
    "        combined_width = resize_size[0] * num_images + margin * (num_images - 1)\n",
    "        combined_height = resize_size[1] + margin  # Add margin for labels\n",
    "    elif num_images == 4:\n",
    "        combined_width = resize_size[0] * 2 + margin\n",
    "        combined_height = resize_size[1] * 2 + margin * 2  # Add margin for labels\n",
    "    elif num_images == 6:\n",
    "        combined_width = resize_size[0] * 3 + margin * 2\n",
    "        combined_height = resize_size[1] * 2 + margin * 2  # Add margin for labels\n",
    "    elif num_images == 9:\n",
    "        combined_width = resize_size[0] * 3 + margin * 2\n",
    "        combined_height = resize_size[1] * 3 + margin * 3  # Add margin for labels\n",
    "    else:\n",
    "        raise ValueError(\"The number of images must be 2, 3, 4, 6, or 9.\")\n",
    "    \n",
    "    # Create new image with white background\n",
    "    combined_image = Image.new('RGB', (combined_width, combined_height), (255, 255, 255))\n",
    "    \n",
    "    # Define positions for each image and label\n",
    "    positions = []\n",
    "    labels = []\n",
    "    if num_images == 2 or num_images == 3:\n",
    "        for i in range(num_images):\n",
    "            x = i * (resize_size[0] + margin)\n",
    "            y = 0+margin\n",
    "            positions.append((x, y))\n",
    "            labels.append(f\"Image{i+1}\")\n",
    "    elif num_images == 4:\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                x = j * (resize_size[0] + margin)\n",
    "                y = i * (resize_size[1] + margin)+margin\n",
    "                positions.append((x, y))\n",
    "                labels.append(f\"Image{2*i+j+1}\")\n",
    "    elif num_images == 6:\n",
    "        for i in range(2):\n",
    "            for j in range(3):\n",
    "                x = j * (resize_size[0] + margin)\n",
    "                y = i * (resize_size[1] + margin)+margin\n",
    "                positions.append((x, y))\n",
    "                labels.append(f\"Image{3*i+j+1}\")\n",
    "    elif num_images == 9:\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                x = j * (resize_size[0] + margin)\n",
    "                y = i * (resize_size[1] + margin)+margin\n",
    "                positions.append((x, y))\n",
    "                labels.append(f\"Image{3*i+j+1}\")\n",
    "    \n",
    "    # Paste images and draw labels\n",
    "    draw = ImageDraw.Draw(combined_image)\n",
    "    font = ImageFont.truetype(\"Arial.ttf\", 36)  # Load a larger TrueType font, or use another available font\n",
    "\n",
    "    for img, pos, label in zip(images, positions, labels):\n",
    "        combined_image.paste(img, pos)\n",
    "        # Calculate label position in the left top corner\n",
    "        label_x = pos[0] + 20  # Add some padding from the left edge\n",
    "        label_y = pos[1] - 40  # Add some padding from the top edge\n",
    "        draw.text((label_x, label_y), label, (0, 0, 0), font=font)\n",
    "    \n",
    "    # Save the combined image\n",
    "    combined_image.save(output_path)\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# image_list = [\n",
    "#     \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/car1.jpg\",\n",
    "#     \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/car2.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/newcar3.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/newcar4.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/apple.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/bear.png\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/apple.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/apple.jpg\",\n",
    "#     # \"/mnt/petrelfs/liuziyu/RLHF/Observation/pics/apple.jpg\",\n",
    "# ]\n",
    "# output_path = \"./combined_image_9.png\"\n",
    "# combine_images_with_labels(image_list, output_path)\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17c89af9-cacd-470f-bba8-2e66da433e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def contains_bbox(s):\n",
    "    bbox_pattern = r'\\[\\s*\\d+(\\.\\d+)?,\\s*\\d+(\\.\\d+)?,\\s*\\d+(\\.\\d+)?,\\s*\\d+(\\.\\d+)?\\s*\\]'\n",
    "    match = re.search(bbox_pattern, s)\n",
    "    if match:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "contains_bbox(\"There is a bbox [0.92,0.32,0.12,0.24]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a086f211-aee8-4ac0-a731-a9604c5decba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187383\n"
     ]
    }
   ],
   "source": [
    "all_images = []\n",
    "for data in dpo_data:\n",
    "    all_images.append(data[\"image\"])\n",
    "print(len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37fcd72e-ab22-45e3-8ce8-b45c9042700a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25925\n",
      "14535\n",
      "146923\n"
     ]
    }
   ],
   "source": [
    "count_vg = 0\n",
    "count_coco_bbox = 0\n",
    "dpo_data_no_bbox = []\n",
    "for item in dpo_data:\n",
    "    if item[\"image\"].split(\"/\")[0]==\"vg\":\n",
    "        count_vg += 1\n",
    "    elif item[\"image\"].split(\"/\")[0]==\"coco\":\n",
    "        flage_bbox = False\n",
    "        for conv in item[\"conversations\"]:\n",
    "            conv_value = conv[\"value\"]\n",
    "            if contains_bbox(conv_value):\n",
    "                flage_bbox = True\n",
    "                break\n",
    "        if flage_bbox == True:\n",
    "            count_coco_bbox += 1\n",
    "        else:\n",
    "            dpo_data_no_bbox.append(item)\n",
    "    else:\n",
    "        dpo_data_no_bbox.append(item)\n",
    "print(count_vg)\n",
    "print(count_coco_bbox)\n",
    "print(len(dpo_data_no_bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7468b4ba-d3d8-4762-bf6b-14101ddc4d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000319154\n",
      "000000169014\n",
      "48000 28000 28000 21000 21000\n"
     ]
    }
   ],
   "source": [
    "original_list = dpo_data_no_bbox\n",
    "print(original_list[0][\"id\"])\n",
    "random.shuffle(original_list)\n",
    "print(original_list[0][\"id\"])\n",
    "sublist1 = original_list[:48000]\n",
    "sublist2 = original_list[48000:76000]\n",
    "sublist3 = original_list[76000:104000]\n",
    "sublist4 = original_list[104000:125000]\n",
    "sublist5 = original_list[125000:146000]\n",
    "\n",
    "print(len(sublist1), len(sublist2), len(sublist3), len(sublist4), len(sublist5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e1e373c-aaac-4d44-ab28-fb972d3329c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "14000\n",
      "7000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "new_sublist2 = []\n",
    "for i in range(0, len(sublist2), 2):\n",
    "    pair = [sublist2[i], sublist2[i + 1]]\n",
    "    new_sublist2.append(pair)\n",
    "print(len(new_sublist2))\n",
    "\n",
    "new_sublist3 = []\n",
    "for i in range(0, len(sublist3), 2):\n",
    "    pair = [sublist3[i], sublist3[i + 1]]\n",
    "    new_sublist3.append(pair)\n",
    "print(len(new_sublist3))\n",
    "\n",
    "new_sublist4 = []\n",
    "for i in range(0, len(sublist4), 3):\n",
    "    pair = [sublist4[i], sublist4[i + 1], sublist4[i + 2]]\n",
    "    new_sublist4.append(pair)\n",
    "print(len(new_sublist4))\n",
    "\n",
    "new_sublist5 = []\n",
    "for i in range(0, len(sublist5), 3):\n",
    "    pair = [sublist5[i], sublist5[i + 1], sublist5[i + 2]]\n",
    "    new_sublist5.append(pair)\n",
    "print(len(new_sublist5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1087e3b2-6b9d-400f-89d4-1be6e348e9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to ./sublist1.json\n",
      "Data has been written to ./new_sublist2.json\n",
      "Data has been written to ./new_sublist3.json\n",
      "Data has been written to ./new_sublist4.json\n",
      "Data has been written to ./new_sublist5.json\n"
     ]
    }
   ],
   "source": [
    "output_json_path = \"./sublist1.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(sublist1, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")\n",
    "\n",
    "output_json_path = \"./new_sublist2.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(new_sublist2, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")\n",
    "\n",
    "output_json_path = \"./new_sublist3.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(new_sublist3, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")\n",
    "\n",
    "output_json_path = \"./new_sublist4.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(new_sublist4, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")\n",
    "\n",
    "output_json_path = \"./new_sublist5.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(new_sublist5, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c490e27e-0e0d-4295-ab7a-de0e6ff197d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48000it [39:41, 20.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "Data has been written to ./ping_sublist1.json\n"
     ]
    }
   ],
   "source": [
    "with open(\"./sublist1.json\", 'r', encoding='utf-8') as file:\n",
    "    sublist1 = json.load(file)\n",
    "print(len(sublist1))\n",
    "\n",
    "ping_sublist1 = []\n",
    "for index, data in tqdm(enumerate(sublist1)):\n",
    "    \n",
    "    image_list = find_companions(data['image'], all_images, 1)\n",
    "    \n",
    "    image_list.append(data['image'])\n",
    "    random.shuffle(image_list)\n",
    "    image_index = image_list.index(data['image'])\n",
    "    new_image_list = []\n",
    "    for img_path in image_list:\n",
    "        new_image_list.append('/mnt/petrelfs/liuziyu/V3Det/LLaVA/scripts/v1_5/data/cl_data/' + img_path)\n",
    "    output_path = f'/mnt/hwfile/mllm/liuziyu/RLHF_data/RLHF_combined_pics_multirounds/sublist1_{index}.jpg'\n",
    "    combine_images_with_labels(new_image_list, output_path)\n",
    "\n",
    "    image_index += 1\n",
    "    image_length = len(image_list)\n",
    "    \n",
    "\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "    data[\"conversations\"][0]['value'] = data[\"conversations\"][0]['value'].replace('<image>', '')\n",
    "    for convs_index, convs in enumerate(data[\"conversations\"]):\n",
    "        if convs['from'] == 'human':\n",
    "            if convs_index == 0:\n",
    "                convs['value'] = '<image>\\n' + f'In Image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            else:\n",
    "                convs['value'] = f'In image{image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "    data['image'] = output_path\n",
    "    ping_sublist1.append(data)\n",
    "\n",
    "print(len(ping_sublist1))\n",
    "output_json_path = \"./ping_sublist1.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(ping_sublist1, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a3978e-ceca-436f-baa3-debcc03a0527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14000it [14:31, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "Data has been written to ./ping_sublist2.json\n"
     ]
    }
   ],
   "source": [
    "with open(\"./new_sublist2.json\", 'r', encoding='utf-8') as file:\n",
    "    new_sublist2 = json.load(file)\n",
    "print(len(new_sublist2))\n",
    "\n",
    "ping_sublist2 = []\n",
    "for index, data in tqdm(enumerate(new_sublist2)):\n",
    "    data_image_list = [item[\"image\"] for item in data]\n",
    "    image_list = find_companions(data_image_list, all_images, 1)\n",
    "    \n",
    "    image_list.extend(data_image_list)\n",
    "    random.shuffle(image_list)\n",
    "    image_index_1 = image_list.index(data_image_list[0])\n",
    "    image_index_2 = image_list.index(data_image_list[1])\n",
    "    new_image_list = []\n",
    "    for img_path in image_list:\n",
    "        new_image_list.append('/mnt/petrelfs/liuziyu/V3Det/LLaVA/scripts/v1_5/data/cl_data/' + img_path)\n",
    "    output_path = f'/mnt/hwfile/mllm/liuziyu/RLHF_data/RLHF_combined_pics_multirounds/sublist2_{index}.jpg'\n",
    "    combine_images_with_labels(new_image_list, output_path)\n",
    "\n",
    "    image_index = [image_index_1+1, image_index_2+1]\n",
    "    image_length = len(image_list)\n",
    "\n",
    "    new_data = {}\n",
    "    new_data[\"id\"] = str(data[0][\"id\"]) + \"_\" + str(data[1][\"id\"])\n",
    "    new_data['image'] = output_path\n",
    "    new_data['conversations'] = []\n",
    "    for i in range(len(data_image_list)):\n",
    "        data[i][\"conversations\"][0]['value'] = data[i][\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "        data[i][\"conversations\"][0]['value'] = data[i][\"conversations\"][0]['value'].replace('<image>', '')\n",
    "        local_image_index = image_index[i]\n",
    "        if i == 0:\n",
    "            for convs_index, convs in enumerate(data[i][\"conversations\"]):\n",
    "                if convs['from'] == 'human':\n",
    "                    if convs_index == 0:\n",
    "                        convs['value'] = '<image>\\n' + f'In Image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                    else:\n",
    "                        convs['value'] = f'In image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            new_data['conversations'].extend(data[i][\"conversations\"])\n",
    "        else:\n",
    "            for convs_index, convs in enumerate(data[i][\"conversations\"]):\n",
    "                if convs['from'] == 'human':\n",
    "                    if convs_index == 0:\n",
    "                        convs['value'] = f'In Image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                    else:\n",
    "                        convs['value'] = f'In image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            new_data['conversations'].extend(data[i][\"conversations\"])\n",
    "\n",
    "    ping_sublist2.append(new_data)\n",
    "\n",
    "print(len(ping_sublist2))\n",
    "output_json_path = \"./ping_sublist2.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(ping_sublist2, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db1d1d16-9418-48b7-8e27-cdbaf2f501e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14000it [17:23, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "Data has been written to ./ping_sublist3.json\n"
     ]
    }
   ],
   "source": [
    "with open(\"./new_sublist3.json\", 'r', encoding='utf-8') as file:\n",
    "    new_sublist3 = json.load(file)\n",
    "print(len(new_sublist3))\n",
    "\n",
    "ping_sublist3 = []\n",
    "for index, data in tqdm(enumerate(new_sublist3)):\n",
    "    data_image_list = [item[\"image\"] for item in data]\n",
    "    image_list = find_companions(data_image_list, all_images, 2)\n",
    "    \n",
    "    image_list.extend(data_image_list)\n",
    "    random.shuffle(image_list)\n",
    "    image_index_1 = image_list.index(data_image_list[0])\n",
    "    image_index_2 = image_list.index(data_image_list[1])\n",
    "    new_image_list = []\n",
    "    for img_path in image_list:\n",
    "        new_image_list.append('/mnt/petrelfs/liuziyu/V3Det/LLaVA/scripts/v1_5/data/cl_data/' + img_path)\n",
    "    output_path = f'/mnt/hwfile/mllm/liuziyu/RLHF_data/RLHF_combined_pics_multirounds/sublist3_{index}.jpg'\n",
    "    combine_images_with_labels(new_image_list, output_path)\n",
    "\n",
    "    image_index = [image_index_1+1, image_index_2+1]\n",
    "    image_length = len(image_list)\n",
    "\n",
    "    new_data = {}\n",
    "    new_data[\"id\"] = str(data[0][\"id\"]) + \"_\" + str(data[1][\"id\"])\n",
    "    new_data['image'] = output_path\n",
    "    new_data['conversations'] = []\n",
    "    for i in range(len(data_image_list)):\n",
    "        data[i][\"conversations\"][0]['value'] = data[i][\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "        data[i][\"conversations\"][0]['value'] = data[i][\"conversations\"][0]['value'].replace('<image>', '')\n",
    "        local_image_index = image_index[i]\n",
    "        if i == 0:\n",
    "            for convs_index, convs in enumerate(data[i][\"conversations\"]):\n",
    "                if convs['from'] == 'human':\n",
    "                    if convs_index == 0:\n",
    "                        convs['value'] = '<image>\\n' + f'In Image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                    else:\n",
    "                        convs['value'] = f'In image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            new_data['conversations'].extend(data[i][\"conversations\"])\n",
    "        else:\n",
    "            for convs_index, convs in enumerate(data[i][\"conversations\"]):\n",
    "                if convs['from'] == 'human':\n",
    "                    if convs_index == 0:\n",
    "                        convs['value'] = f'In Image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                    else:\n",
    "                        convs['value'] = f'In image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            new_data['conversations'].extend(data[i][\"conversations\"])\n",
    "\n",
    "    ping_sublist3.append(new_data)\n",
    "\n",
    "print(len(ping_sublist3))\n",
    "output_json_path = \"./ping_sublist3.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(ping_sublist3, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35c09bb0-c0af-4c25-8ba2-8d0409ea4ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7000it [11:52,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n",
      "Data has been written to ./ping_sublist4.json\n"
     ]
    }
   ],
   "source": [
    "with open(\"./new_sublist4.json\", 'r', encoding='utf-8') as file:\n",
    "    new_sublist4 = json.load(file)\n",
    "print(len(new_sublist4))\n",
    "\n",
    "ping_sublist4 = []\n",
    "for index, data in tqdm(enumerate(new_sublist4)):\n",
    "    data_image_list = [item[\"image\"] for item in data]\n",
    "    image_list = find_companions(data_image_list, all_images, 3)\n",
    "    \n",
    "    image_list.extend(data_image_list)\n",
    "    random.shuffle(image_list)\n",
    "    image_index_1 = image_list.index(data_image_list[0])\n",
    "    image_index_2 = image_list.index(data_image_list[1])\n",
    "    image_index_3 = image_list.index(data_image_list[2])\n",
    "    new_image_list = []\n",
    "    for img_path in image_list:\n",
    "        new_image_list.append('/mnt/petrelfs/liuziyu/V3Det/LLaVA/scripts/v1_5/data/cl_data/' + img_path)\n",
    "    output_path = f'/mnt/hwfile/mllm/liuziyu/RLHF_data/RLHF_combined_pics_multirounds/sublist4_{index}.jpg'\n",
    "    combine_images_with_labels(new_image_list, output_path)\n",
    "\n",
    "    image_index = [image_index_1+1, image_index_2+1, image_index_3+1]\n",
    "    image_length = len(image_list)\n",
    "\n",
    "    new_data = {}\n",
    "    new_data[\"id\"] = str(data[0][\"id\"]) + \"_\" + str(data[1][\"id\"]) + \"_\" + str(data[2][\"id\"])\n",
    "    new_data['image'] = output_path\n",
    "    new_data['conversations'] = []\n",
    "    for i in range(len(data_image_list)):\n",
    "        data[i][\"conversations\"][0]['value'] = data[i][\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "        data[i][\"conversations\"][0]['value'] = data[i][\"conversations\"][0]['value'].replace('<image>', '')\n",
    "        local_image_index = image_index[i]\n",
    "        if i == 0:\n",
    "            for convs_index, convs in enumerate(data[i][\"conversations\"]):\n",
    "                if convs['from'] == 'human':\n",
    "                    if convs_index == 0:\n",
    "                        convs['value'] = '<image>\\n' + f'In Image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                    else:\n",
    "                        convs['value'] = f'In image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            new_data['conversations'].extend(data[i][\"conversations\"])\n",
    "        else:\n",
    "            for convs_index, convs in enumerate(data[i][\"conversations\"]):\n",
    "                if convs['from'] == 'human':\n",
    "                    if convs_index == 0:\n",
    "                        convs['value'] = f'In Image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                    else:\n",
    "                        convs['value'] = f'In image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            new_data['conversations'].extend(data[i][\"conversations\"])\n",
    "\n",
    "    ping_sublist4.append(new_data)\n",
    "\n",
    "print(len(ping_sublist4))\n",
    "output_json_path = \"./ping_sublist4.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(ping_sublist4, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02e3b7ca-84b3-47c5-b94c-7791388c814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7000it [16:21,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n",
      "Data has been written to ./ping_sublist5.json\n"
     ]
    }
   ],
   "source": [
    "with open(\"./new_sublist5.json\", 'r', encoding='utf-8') as file:\n",
    "    new_sublist5 = json.load(file)\n",
    "print(len(new_sublist5))\n",
    "\n",
    "ping_sublist5 = []\n",
    "for index, data in tqdm(enumerate(new_sublist5)):\n",
    "    data_image_list = [item[\"image\"] for item in data]\n",
    "    image_list = find_companions(data_image_list, all_images, 6)\n",
    "    \n",
    "    image_list.extend(data_image_list)\n",
    "    random.shuffle(image_list)\n",
    "    image_index_1 = image_list.index(data_image_list[0])\n",
    "    image_index_2 = image_list.index(data_image_list[1])\n",
    "    image_index_3 = image_list.index(data_image_list[2])\n",
    "    new_image_list = []\n",
    "    for img_path in image_list:\n",
    "        new_image_list.append('/mnt/petrelfs/liuziyu/V3Det/LLaVA/scripts/v1_5/data/cl_data/' + img_path)\n",
    "    output_path = f'/mnt/hwfile/mllm/liuziyu/RLHF_data/RLHF_combined_pics_multirounds/sublist5_{index}.jpg'\n",
    "    combine_images_with_labels(new_image_list, output_path)\n",
    "\n",
    "    image_index = [image_index_1+1, image_index_2+1, image_index_3+1]\n",
    "    image_length = len(image_list)\n",
    "\n",
    "    new_data = {}\n",
    "    new_data[\"id\"] = str(data[0][\"id\"]) + \"_\" + str(data[1][\"id\"]) + \"_\" + str(data[2][\"id\"])\n",
    "    new_data['image'] = output_path\n",
    "    new_data['conversations'] = []\n",
    "    for i in range(len(data_image_list)):\n",
    "        data[i][\"conversations\"][0]['value'] = data[i][\"conversations\"][0]['value'].replace('<image>\\n', '')\n",
    "        data[i][\"conversations\"][0]['value'] = data[i][\"conversations\"][0]['value'].replace('<image>', '')\n",
    "        local_image_index = image_index[i]\n",
    "        if i == 0:\n",
    "            for convs_index, convs in enumerate(data[i][\"conversations\"]):\n",
    "                if convs['from'] == 'human':\n",
    "                    if convs_index == 0:\n",
    "                        convs['value'] = '<image>\\n' + f'In Image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                    else:\n",
    "                        convs['value'] = f'In image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            new_data['conversations'].extend(data[i][\"conversations\"])\n",
    "        else:\n",
    "            for convs_index, convs in enumerate(data[i][\"conversations\"]):\n",
    "                if convs['from'] == 'human':\n",
    "                    if convs_index == 0:\n",
    "                        convs['value'] = f'In Image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "                    else:\n",
    "                        convs['value'] = f'In image{local_image_index}, ' + convs['value'][0].lower() + convs['value'][1:]\n",
    "            new_data['conversations'].extend(data[i][\"conversations\"])\n",
    "\n",
    "    ping_sublist5.append(new_data)\n",
    "\n",
    "print(len(ping_sublist5))\n",
    "output_json_path = \"./ping_sublist5.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(ping_sublist5, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cc9a842-c766-4b25-8a4d-9f6c18ec6935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "14000\n",
      "14000\n",
      "7000\n",
      "7000\n",
      "90000\n",
      "Data has been written to ./ping_llava187k_90k.json\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/ping_sublist1.json\", 'r', encoding='utf-8') as file:\n",
    "    ping_sublist1 = json.load(file)\n",
    "print(len(ping_sublist1))\n",
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/ping_sublist2.json\", 'r', encoding='utf-8') as file:\n",
    "    ping_sublist2 = json.load(file)\n",
    "print(len(ping_sublist2))\n",
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/ping_sublist3.json\", 'r', encoding='utf-8') as file:\n",
    "    ping_sublist3 = json.load(file)\n",
    "print(len(ping_sublist3))\n",
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/ping_sublist4.json\", 'r', encoding='utf-8') as file:\n",
    "    ping_sublist4 = json.load(file)\n",
    "print(len(ping_sublist4))\n",
    "with open(\"/mnt/petrelfs/liuziyu/RLHF/make_data/data_randomsample_randompic_45k/ping_sublist5.json\", 'r', encoding='utf-8') as file:\n",
    "    ping_sublist5 = json.load(file)\n",
    "print(len(ping_sublist5))\n",
    "\n",
    "ping_llava187k_90k = ping_sublist1 + ping_sublist2 + ping_sublist3 + ping_sublist4 + ping_sublist5\n",
    "print(len(ping_llava187k_90k))\n",
    "output_json_path = \"./ping_llava187k_90k.json\"\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(ping_llava187k_90k, json_file, indent=4)\n",
    "print(f\"Data has been written to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd377454-3fb3-4a3d-8799-ff4f8f662e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RH_ENV",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
